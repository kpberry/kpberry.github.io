{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.txt', 'r') as file:\n",
    "    dictionary = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vowel_groups(text):\n",
    "    return sum(map(lambda w: any(map(lambda c: c in 'aeiouy', w)), text.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(sequence, window_sizes=(1, 2)):\n",
    "    result = []\n",
    "    for window_size in range(window_sizes[0], window_sizes[-1] + 1):\n",
    "        for i in range(len(sequence) - (window_size - 1)):\n",
    "            result.append(sequence[i:i + window_size])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(word, mapping):\n",
    "    result = [0] * len(mapping)\n",
    "    for window in get_windows(word.lower()):\n",
    "        if window in mapping:\n",
    "            result[mapping[window]] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_mapping(train_words):\n",
    "    features = set()\n",
    "    for word in train_words:\n",
    "        for window in get_windows(word.lower()):\n",
    "            features.add(window)\n",
    "    mapping = {f: i for i, f in enumerate(sorted(features))}\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_syllables(dictionary):\n",
    "    words = []\n",
    "    syllables = []\n",
    "    for line in dictionary.split('\\n'):\n",
    "        word, pronunciation = line.split('\\t')\n",
    "        word = word.split('(')[0]\n",
    "        syllable_count = count_vowel_groups(pronunciation)\n",
    "        words.append(word)\n",
    "        syllables.append(syllable_count)\n",
    "    return words, syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, syllables = get_words_and_syllables(dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, test_words, train_counts, test_counts = train_test_split(words, syllables, test_size=0.01, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = get_feature_mapping(train_words=train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = csr_matrix([to_one_hot(text, mapping) for text in train_words])\n",
    "X_test = csr_matrix([to_one_hot(text, mapping) for text in test_words])\n",
    "\n",
    "y_train = train_counts\n",
    "y_test = test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.21743553\n",
      "Iteration 2, loss = 0.07597458\n",
      "Iteration 3, loss = 0.06243816\n",
      "Iteration 4, loss = 0.05738227\n",
      "Iteration 5, loss = 0.05492322\n",
      "Iteration 6, loss = 0.05350545\n",
      "Iteration 7, loss = 0.05238199\n",
      "Iteration 8, loss = 0.05163323\n",
      "Iteration 9, loss = 0.05093290\n",
      "Iteration 10, loss = 0.05049456\n",
      "Iteration 11, loss = 0.04991418\n",
      "Iteration 12, loss = 0.04935549\n",
      "Iteration 13, loss = 0.04896825\n",
      "Iteration 14, loss = 0.04848493\n",
      "Iteration 15, loss = 0.04805448\n",
      "Iteration 16, loss = 0.04762846\n",
      "Iteration 17, loss = 0.04721635\n",
      "Iteration 18, loss = 0.04682616\n",
      "Iteration 19, loss = 0.04650857\n",
      "Iteration 20, loss = 0.04615163\n",
      "Iteration 21, loss = 0.04596195\n",
      "Iteration 22, loss = 0.04567895\n",
      "Iteration 23, loss = 0.04538243\n",
      "Iteration 24, loss = 0.04522555\n",
      "Iteration 25, loss = 0.04503857\n",
      "Iteration 26, loss = 0.04474662\n",
      "Iteration 27, loss = 0.04455790\n",
      "Iteration 28, loss = 0.04449934\n",
      "Iteration 29, loss = 0.04425565\n",
      "Iteration 30, loss = 0.04411712\n",
      "Iteration 31, loss = 0.04390123\n",
      "Iteration 32, loss = 0.04378663\n",
      "Iteration 33, loss = 0.04373532\n",
      "Iteration 34, loss = 0.04352384\n",
      "Iteration 35, loss = 0.04340512\n",
      "Iteration 36, loss = 0.04332616\n",
      "Iteration 37, loss = 0.04318572\n",
      "Iteration 38, loss = 0.04315739\n",
      "Iteration 39, loss = 0.04300163\n",
      "Iteration 40, loss = 0.04296864\n",
      "Iteration 41, loss = 0.04285565\n",
      "Iteration 42, loss = 0.04277374\n",
      "Iteration 43, loss = 0.04267015\n",
      "Iteration 44, loss = 0.04255198\n",
      "Iteration 45, loss = 0.04254175\n",
      "Iteration 46, loss = 0.04243007\n",
      "Iteration 47, loss = 0.04235178\n",
      "Iteration 48, loss = 0.04229758\n",
      "Iteration 49, loss = 0.04224672\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(10,), verbose=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8903080390683696\n",
      "0.10314131582729456\n",
      "0.19365153167673282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       0.92      0.94      0.93       165\n",
      "        2.0       0.93      0.93      0.93       624\n",
      "        3.0       0.87      0.84      0.86       357\n",
      "        4.0       0.79      0.83      0.81       129\n",
      "        5.0       0.73      0.78      0.75        45\n",
      "        6.0       0.75      0.60      0.67        10\n",
      "        7.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1331\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0]\n",
      " [  1 155   8   1   0   0   0   0]\n",
      " [  0  11 582  31   0   0   0   0]\n",
      " [  0   1  35 300  21   0   0   0]\n",
      " [  0   0   1  12 107   9   0   0]\n",
      " [  0   1   0   0   8  35   1   0]\n",
      " [  0   0   0   0   0   4   6   0]\n",
      " [  0   0   0   0   0   0   1   0]]\n",
      "0.00243605359317905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "raw_pred = clf.predict(X_test)\n",
    "pred = np.round(raw_pred)\n",
    "print(accuracy_score(y_true=y_test, y_pred=pred))\n",
    "print(mean_squared_error(y_true=y_test, y_pred=raw_pred))\n",
    "print(mean_absolute_error(y_true=y_test, y_pred=raw_pred))\n",
    "print(classification_report(y_true=y_test, y_pred=pred))\n",
    "print(confusion_matrix(y_true=y_test, y_pred=pred))\n",
    "print(abs(np.sum(y_test) - np.sum(pred)) / np.sum(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196840\n"
     ]
    }
   ],
   "source": [
    "from sklearn_porter import Porter\n",
    "porter = Porter(clf, language='js')\n",
    "output = porter.export(embed_data=True)\n",
    "print(len(output))\n",
    "with open('syllable_counter.js', 'w') as out:\n",
    "    out.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word:supercalifragilisticexpialidocious\n",
      "supercalifragilisticexpialidocious has about 14 syllables\n",
      "(guess: 14.19)\n",
      "Enter a word:floccinaucinihilipilification\n",
      "floccinaucinihilipilification has about 12 syllables\n",
      "(guess: 12.01)\n",
      "Enter a word:umonoultramicroscopicsilicovolcanoconiosis\n",
      "umonoultramicroscopicsilicovolcanoconiosis has about 18 syllables\n",
      "(guess: 17.82)\n",
      "Enter a word:forty-two\n",
      "forty-two has about 3 syllables\n",
      "(guess: 3.18)\n",
      "Enter a word:q\n",
      "q has about 1 syllables\n",
      "(guess: 1.01)\n"
     ]
    }
   ],
   "source": [
    "word = None\n",
    "while word != 'q':\n",
    "    word = input('Enter a word:')\n",
    "    guess = clf.predict([to_one_hot(word, mapping)])[0]\n",
    "    print('{} has about {} syllables'.format(word, int(np.round(guess))))\n",
    "    print('(guess: {:.2f})'.format(guess))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
